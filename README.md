![ime](https://user-images.githubusercontent.com/2136700/160290194-4f30a796-876a-4750-bb3b-b5b62c4676c5.png)
# Transformers4IME

*å…¶ä»–è¯­è¨€ç‰ˆæœ¬: [English](README.en.md)

Transformers4IMEæ˜¯å°è¯•å°†é¢„è®­ç»ƒæ¨¡å‹è¿ç”¨äºè¾“å…¥æ³•çš„è½¯ä»¶åŒ…ã€‚

## PinyinGPT

PinyinGPTæ¨¡å‹æºäºæˆ‘ä»¬å‘è¡¨äºACL2022çš„å·¥ä½œ [Exploring and Adapting Chinese GPT to Pinyin Input Method](https://arxiv.org/abs/2203.00249) ã€‚
```bibtex
@inproceedings{tan-etal-2022-exploring,
    title = "Exploring and Adapting {C}hinese {GPT} to {P}inyin Input Method",
    author = "Tan, Minghuan  and
      Dai, Yong  and
      Tang, Duyu  and
      Feng, Zhangyin  and
      Huang, Guoping  and
      Jiang, Jing  and
      Li, Jiwei  and
      Shi, Shuming",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.133",
    doi = "10.18653/v1/2022.acl-long.133",
    pages = "1899--1909",
    abstract = "While GPT has become the de-facto method for text generation tasks, its application to pinyin input method remains unexplored.In this work, we make the first exploration to leverage Chinese GPT for pinyin input method.We find that a frozen GPT achieves state-of-the-art performance on perfect pinyin.However, the performance drops dramatically when the input includes abbreviated pinyin.A reason is that an abbreviated pinyin can be mapped to many perfect pinyin, which links to even larger number of Chinese characters.We mitigate this issue with two strategies,including enriching the context with pinyin and optimizing the training process to help distinguish homophones. To further facilitate the evaluation of pinyin input method, we create a dataset consisting of 270K instances from fifteen domains.Results show that our approach improves the performance on abbreviated pinyin across all domains.Model analysis demonstrates that both strategiescontribute to the performance boost.",
}
```
æœ¬æ–‡ä¸»è¦ç ”ç©¶äº†å°†ä¸­æ–‡GPTçš„é¢„è®­ç»ƒæ¨¡å‹é€‚é…åˆ°æ‹¼éŸ³è¾“å…¥æ³•çš„é—®é¢˜ã€‚æˆ‘ä»¬å‘ç°ï¼Œåœ¨GPTçš„å¹¿æ³›ä½¿ç”¨ä¸­ï¼Œä»ç„¶ç¼ºå°‘å¯¹æ‹¼éŸ³è¾“å…¥æ³•çš„æ¢ç´¢ã€‚
ç»è¿‡å¯¹ç”Ÿæˆè¿‡ç¨‹åŠ ä¸Šæ‹¼éŸ³çš„é™åˆ¶ï¼Œå…¨æ‹¼åœºæ™¯ä¸‹çš„GPTçš„æ•ˆæœååˆ†çªå‡ºï¼Œåœ¨ä¼ ç»Ÿçš„æ•°æ®é›†ä¸Šå°±èƒ½è¾¾åˆ°SOTAã€‚
ç„¶è€Œï¼Œå¯¹äºé¦–å­—æ¯çš„æƒ…å½¢ï¼ŒGPTçš„æ•ˆæœå‡ºç°å¤§å¹…ä¸‹æ»‘ï¼Œè¿™ä¸åŒå£°æ¯å­—çš„å€™é€‰å¤§å¹…å¢åŠ ç›¸å…³ã€‚
æˆ‘ä»¬é‡‡å–ä¸¤ç§ç­–ç•¥æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä¸€æ–¹é¢è®©æ¨¡å‹å……åˆ†ä½¿ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯å’Œæ‹¼éŸ³ä¿¡æ¯ï¼Œå¦ä¸€æ–¹é¢å¢å¼ºè®­ç»ƒè¿‡ç¨‹ä¸­å¯¹åŒå£°æ¯å­—çš„è¾¨æã€‚
ä¸ºäº†åŠ©åŠ›æ‹¼éŸ³è¾“å…¥æ³•çš„è¯„æµ‹ï¼Œæˆ‘ä»¬åŸºäºæœ€æ–°çš„è¯­æ–™ï¼Œæ„å»ºäº†è·¨15ä¸ªæ–°é—»é¢†åŸŸçš„270kçš„æµ‹è¯•é›†åˆï¼Œé›†åˆçš„æ ·æœ¬è¦†ç›–å¤šç§ä¸Šæ–‡çš„é•¿åº¦å’Œé¢„æµ‹é•¿åº¦ç»„åˆã€‚
é€šè¿‡å¯¹æ¨¡å‹çš„åˆ†æå’Œæ¶ˆèï¼Œæˆ‘ä»¬å‘ç°æ¨¡å‹çš„ä¸¤ä¸ªç­–ç•¥éƒ½å¯¹æœ€åçš„æ•ˆæœæœ‰ä¿ƒè¿›ä½œç”¨ã€‚
å®éªŒç»“æœå¯¹è¾“å…¥æ³•çš„ç ”ç©¶å…·æœ‰å‚è€ƒæ„ä¹‰ã€‚

![pinyinGPT-method](https://user-images.githubusercontent.com/2136700/160290180-ad531d81-4d47-48a9-a924-001780d5c5cf.png)

_è¯­æ–™æ•´ç†_

ä¾‹å¦‚ï¼Œå¤„ç†æ‹¼éŸ³çš„ç›¸å…³è¯­æ–™æ—¶, æˆ‘ä»¬ä¼šå¾—åˆ°å¦‚ä¸‹æ•°æ®æ ¼å¼
```python
{'words': [['è§‚ä¼—', 'å§¥çˆ·'], ['ï¼Œ'], ['å¦‚æœ', 'ä½ ', 'æœ‰', 'è¶…ç¥', 'è¶…', 'ç§€'], ['ã€'], ['å‘çˆ¹', 'æç¬‘', 'ç´ æ'], ['ï¼Œ'],
           ['æ¬¢è¿', 'ç»™', 'è‹', 'å§', 'æŠ•ç¨¿'], ['ï¼Œ'], ['é‡‡ç”¨', 'æœ‰å¥–', 'å“¦'], ['ï¼']],
 'tokens': [[['è§‚', 'ä¼—'], ['å§¥', 'çˆ·']], ['ï¼Œ'], [['å¦‚', 'æœ'], ['ä½ '], ['æœ‰'], ['è¶…', 'ç¥'], ['è¶…'], ['ç§€']], ['ã€'],
            [['å‘', 'çˆ¹'], ['æ', 'ç¬‘'], ['ç´ ', 'æ']], ['ï¼Œ'], [['æ¬¢', 'è¿'], ['ç»™'], ['è‹'], ['å§'], ['æŠ•', 'ç¨¿']], ['ï¼Œ'],
            [['é‡‡', 'ç”¨'], ['æœ‰', 'å¥–'], ['å“¦']], ['ï¼']],
 'pinyin': [[['guan', 'zhong'], ['lao', 'ye']], ['ï¼Œ'],
            [['ru', 'guo'], ['ni'], ['you'], ['chao', 'shen'],
             ['chao'], ['xiu']], ['ã€'],
            [['keng', 'die'], ['gao', 'xiao'], ['su', 'cai']],
            ['ï¼Œ'], [['huan', 'ying'], ['gei'], ['cang'], ['jie'],
                    ['tou', 'gao']], ['ï¼Œ'],
            [['cai', 'yong'], ['you', 'jiang'], ['o']], ['ï¼']],
 'abbr': [[['g', 'z'], ['l', 'y']], ['ï¼Œ'], [['r', 'g'], ['n'], ['y'], ['c', 's'], ['c'], ['x']], ['ã€'],
          [['k', 'd'], ['g', 'x'], ['s', 'c']], ['ï¼Œ'], [['h', 'y'], ['g'], ['c'], ['j'], ['t', 'g']], ['ï¼Œ'],
          [['c', 'y'], ['y', 'j'], ['o']], ['ï¼']]}
```


é€‰å®šéœ€è¦çš„dbæ–‡ä»¶è¿›è¡Œåˆå¹¶é€šè¿‡transformersæ”¯æŒçš„tokenizerè½¬æ¢æˆ`token id`ï¼Œå¾—åˆ°ä¸€ä¸ªæ¨¡å‹å¯ç›´æ¥ä½¿ç”¨çš„`txt_db`ã€‚

```shell
PYTHONPATH=src RAW_DIR=data/raw ANNOTATION_DIR=data/annotations_db TXT_DIR=data/txt_db python convert.py --domain CLUECorpusSmall --genre news2016zh_corpus --config=config/gpt2zh/pretrain_pinyin.json --use_proxy
```



```
PYTHONPATH=src RAW_DIR=data/raw ANNOTATION_DIR=data/annotations_db2 TXT_DIR=data/txt_db ANNOTATOR_TAGGER=whitespace ADDITIONAL_SPECIAL_TOKENS=data/pretrained/additional_special_tokens.json PRETRAINED_MODEL_NAME_OR_PATH=data/pretrained/uer/gpt2-chinese-cluecorpussmall python convert.py --domain 300g_word --genre train.txt07 --config=config/gpt2zh/pretrain_pinyin.json --use_proxy --split train
```

_æ¨¡å‹åˆ—è¡¨_

* GPT2
    * GPT2-Public (uer/gpt2-chinese-cluecorpussmall) [ğŸ¤— models](https://huggingface.co/uer/gpt2-chinese-cluecorpussmall)
    * GPT2-Ours (visualjoyce/gpt2-zh-21k) [ğŸ¤— models](https://huggingface.co/aihijo/gpt2-zh-21k)
* PinyinGPT2Concat
    * Directly
    * Segmented (visualjoyce/transformers4ime-pinyingpt-concat) [ğŸ¤— models](https://huggingface.co/aihijo/transformers4ime-pinyingpt-concat)
* PinyinGPT2Compose
    * PinyinGPT2ComposeBottom
    * PinyinGPT2ComposeTop
        * logits
        * states
        * residual

_è®­ç»ƒæ¨¡å¼_

* AbbrOnly å…¨ç¼©å†™
* PinyinOnly å…¨æ‹¼éŸ³
* PinyinAbbr æ··åˆæ¨¡å¼

```shell
sh pretrain_pinyingpt.sh
```

_åŸºçº¿æµ‹è¯•_

åŸºçº¿è¯„æµ‹æ•°æ®é›†åœ°å€

* [ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1YEG54GSRfPzKO2gQD1IiHw?pwd=7j6v)

![99E333F0B1C6D7B67ACB9D9E61A73DA8](https://user-images.githubusercontent.com/2136700/160289844-924ef07f-b983-4e9c-b07a-45ad042e17da.png)


PDåŸºçº¿æµ‹è¯•
```shell
python3 benchmarks.py --samples_json data/benchmarks/PD/samples_0.json \
  --pretrained_model_name_or_path data/pretrained_models/gpt2-zh-ours \
  --additional_special_tokens data/pretrained/additional_special_tokens.json \
  --pinyin2char_json data/pretrained/pinyin2char.json \
  --pinyin_logits_processor_cls pinyingpt-compatible \
  --num_beams 16 \
  --abbr_mode none
```

æ”¯æŒå¯¹ç‰¹å®šæ¨¡å‹çš„ç‰¹å®šcheckpointè¿›è¡Œè¯„æµ‹
```shell
sh benchmarks.sh pinyingpt-concat data/output/pinyingpt \
  data/output/models/ckpt50000/pytorch_model.bin
```

_é¸£è°¢_

è¯¥å·¥ä½œåœ¨è…¾è®¯AI Labå®ä¹ æœŸé—´å®Œæˆã€‚
